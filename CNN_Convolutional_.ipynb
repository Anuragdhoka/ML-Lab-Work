{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHDWb8jzkqI3"
      },
      "source": [
        "# Part 1: Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eAxVZg8kqI6"
      },
      "source": [
        "###  Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4CSTapDRkqI9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "from keras.models import Model\n",
        "import timeit\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "3otQrU4JWLej"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEKUqkgGkqJI"
      },
      "source": [
        "### Preparing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtwFbXyskqJL",
        "outputId": "d95fea28-8a90-4728-8499-581220a32771"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test =to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2A1KfUskqJT"
      },
      "source": [
        "### Building a Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMtSvqMdkqJV",
        "outputId": "b9d8cfc8-07a4-4c58-8b83-fc290a7b0e43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 13, 13, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 11, 11, 16)        4624      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 5, 5, 16)          0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 100)               40100     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 46,054\n",
            "Trainable params: 46,054\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Aab-hxdkqJc"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MWvDXQgkqJf",
        "outputId": "a32923b1-3c46-4c3a-c81d-e9d8994e4fed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.4081 - accuracy: 0.8703 - val_loss: 0.0829 - val_accuracy: 0.9731\n",
            "Epoch 2/50\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.1499 - accuracy: 0.9544 - val_loss: 0.0576 - val_accuracy: 0.9810\n",
            "Epoch 3/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.1184 - accuracy: 0.9632 - val_loss: 0.0450 - val_accuracy: 0.9840\n",
            "Epoch 4/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.1021 - accuracy: 0.9698 - val_loss: 0.0365 - val_accuracy: 0.9879\n",
            "Epoch 5/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0893 - accuracy: 0.9726 - val_loss: 0.0338 - val_accuracy: 0.9887\n",
            "Epoch 6/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0810 - accuracy: 0.9760 - val_loss: 0.0312 - val_accuracy: 0.9906\n",
            "Epoch 7/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0768 - accuracy: 0.9765 - val_loss: 0.0318 - val_accuracy: 0.9894\n",
            "Epoch 8/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0722 - accuracy: 0.9779 - val_loss: 0.0305 - val_accuracy: 0.9897\n",
            "Epoch 9/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0669 - accuracy: 0.9801 - val_loss: 0.0278 - val_accuracy: 0.9909\n",
            "Epoch 10/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0646 - accuracy: 0.9801 - val_loss: 0.0254 - val_accuracy: 0.9917\n",
            "Epoch 11/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0610 - accuracy: 0.9817 - val_loss: 0.0262 - val_accuracy: 0.9918\n",
            "Epoch 12/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0588 - accuracy: 0.9818 - val_loss: 0.0276 - val_accuracy: 0.9916\n",
            "Epoch 13/50\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.0594 - accuracy: 0.9816 - val_loss: 0.0257 - val_accuracy: 0.9925\n",
            "Epoch 14/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0544 - accuracy: 0.9835 - val_loss: 0.0247 - val_accuracy: 0.9915\n",
            "Epoch 15/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0559 - accuracy: 0.9822 - val_loss: 0.0235 - val_accuracy: 0.9921\n",
            "Epoch 16/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0533 - accuracy: 0.9835 - val_loss: 0.0234 - val_accuracy: 0.9927\n",
            "Epoch 17/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0515 - accuracy: 0.9836 - val_loss: 0.0250 - val_accuracy: 0.9916\n",
            "Epoch 18/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0491 - accuracy: 0.9847 - val_loss: 0.0229 - val_accuracy: 0.9929\n",
            "Epoch 19/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0490 - accuracy: 0.9847 - val_loss: 0.0245 - val_accuracy: 0.9917\n",
            "Epoch 20/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0500 - accuracy: 0.9845 - val_loss: 0.0225 - val_accuracy: 0.9922\n",
            "Epoch 21/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0463 - accuracy: 0.9859 - val_loss: 0.0244 - val_accuracy: 0.9921\n",
            "Epoch 22/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0460 - accuracy: 0.9857 - val_loss: 0.0217 - val_accuracy: 0.9931\n",
            "Epoch 23/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0421 - accuracy: 0.9870 - val_loss: 0.0220 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0432 - accuracy: 0.9864 - val_loss: 0.0248 - val_accuracy: 0.9921\n",
            "Epoch 25/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0433 - accuracy: 0.9863 - val_loss: 0.0234 - val_accuracy: 0.9917\n",
            "Epoch 26/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0417 - accuracy: 0.9868 - val_loss: 0.0223 - val_accuracy: 0.9928\n",
            "Epoch 27/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0415 - accuracy: 0.9872 - val_loss: 0.0223 - val_accuracy: 0.9925\n",
            "Epoch 28/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0427 - accuracy: 0.9865 - val_loss: 0.0222 - val_accuracy: 0.9921\n",
            "Epoch 29/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0432 - accuracy: 0.9868 - val_loss: 0.0240 - val_accuracy: 0.9915\n",
            "Epoch 30/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0407 - accuracy: 0.9872 - val_loss: 0.0216 - val_accuracy: 0.9916\n",
            "Epoch 31/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0399 - accuracy: 0.9872 - val_loss: 0.0230 - val_accuracy: 0.9924\n",
            "Epoch 32/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0405 - accuracy: 0.9871 - val_loss: 0.0231 - val_accuracy: 0.9925\n",
            "Epoch 33/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0382 - accuracy: 0.9883 - val_loss: 0.0233 - val_accuracy: 0.9926\n",
            "Epoch 34/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0380 - accuracy: 0.9879 - val_loss: 0.0243 - val_accuracy: 0.9925\n",
            "Epoch 35/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0352 - accuracy: 0.9888 - val_loss: 0.0219 - val_accuracy: 0.9927\n",
            "Epoch 36/50\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.0377 - accuracy: 0.9885 - val_loss: 0.0232 - val_accuracy: 0.9917\n",
            "Epoch 37/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0383 - accuracy: 0.9879 - val_loss: 0.0228 - val_accuracy: 0.9921\n",
            "Epoch 38/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0352 - accuracy: 0.9890 - val_loss: 0.0222 - val_accuracy: 0.9924\n",
            "Epoch 39/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0369 - accuracy: 0.9884 - val_loss: 0.0231 - val_accuracy: 0.9924\n",
            "Epoch 40/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0370 - accuracy: 0.9884 - val_loss: 0.0221 - val_accuracy: 0.9927\n",
            "Epoch 41/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0361 - accuracy: 0.9884 - val_loss: 0.0234 - val_accuracy: 0.9932\n",
            "Epoch 42/50\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.0370 - accuracy: 0.9885 - val_loss: 0.0200 - val_accuracy: 0.9938\n",
            "Epoch 43/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0344 - accuracy: 0.9890 - val_loss: 0.0210 - val_accuracy: 0.9935\n",
            "Epoch 44/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0353 - accuracy: 0.9883 - val_loss: 0.0221 - val_accuracy: 0.9930\n",
            "Epoch 45/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0336 - accuracy: 0.9889 - val_loss: 0.0223 - val_accuracy: 0.9927\n",
            "Epoch 46/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0349 - accuracy: 0.9888 - val_loss: 0.0226 - val_accuracy: 0.9921\n",
            "Epoch 47/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0336 - accuracy: 0.9891 - val_loss: 0.0226 - val_accuracy: 0.9928\n",
            "Epoch 48/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0331 - accuracy: 0.9891 - val_loss: 0.0224 - val_accuracy: 0.9932\n",
            "Epoch 49/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0333 - accuracy: 0.9893 - val_loss: 0.0243 - val_accuracy: 0.9929\n",
            "Epoch 50/50\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0331 - accuracy: 0.9895 - val_loss: 0.0222 - val_accuracy: 0.9933\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5f557d5890>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=\"adam\",\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gprccy28kqJn"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74OuyWUkkqJq",
        "outputId": "c1772e90-e3b0-4085-af16-1157a585b4b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.022164877504110336\n",
            "Test accuracy: 0.9933000206947327\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScMO1hxHkqJw"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "IHv0D_xhkqJx",
        "outputId": "e1ae5456-2641-4959-db90-a558965a4555"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import pylab as plt\n",
        "\n",
        "plt.imshow(x_test[122].reshape(28,28),cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFYYp7JEaHoj",
        "outputId": "c32d1eec-6f82-4695-e0fa-cf10e708206c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "import numpy as np\n",
        "li=[0.5, 0,0.4, 0,0,0]\n",
        "li=np.array(li)\n",
        "thresholded = (li>=0.5)*1\n",
        "thresholded "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ffffzwBkqJ3",
        "scrolled": true,
        "outputId": "2503f186-29d7-4c99-d465-6254ec86d097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction Score:\n",
            " [4.4959827e-17 1.3910924e-08 8.7462954e-12 9.3724632e-11 4.6323334e-10\n",
            " 4.8262169e-14 2.4765285e-20 1.0000000e+00 9.9627287e-15 1.2862011e-09]\n",
            "\n",
            "Thresholded Score:\n",
            " [0 0 0 0 0 0 0 1 0 0]\n",
            "\n",
            "Predicted Digit:\n",
            " [7]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "prediction = model.predict(x_test[122:123])\n",
        "print('Prediction Score:\\n',prediction[0])\n",
        "thresholded = (prediction>0.5)*1\n",
        "print('\\nThresholded Score:\\n',thresholded[0])\n",
        "print('\\nPredicted Digit:\\n',np.where(thresholded == 1)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKT5OJSVkqJ8"
      },
      "source": [
        "# Part 2: Applications of Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzUY5QxykqJ_"
      },
      "source": [
        "###  MobileNet Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVPVmwIZkqKA",
        "outputId": "2bf9df04-a6d6-48bf-bc17-2bc9f53a5668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mobilenet_0.25_224\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv1 (Conv2D)              (None, 112, 112, 8)       216       \n",
            "                                                                 \n",
            " conv1_bn (BatchNormalizatio  (None, 112, 112, 8)      32        \n",
            " n)                                                              \n",
            "                                                                 \n",
            " conv1_relu (ReLU)           (None, 112, 112, 8)       0         \n",
            "                                                                 \n",
            " conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 8)      72        \n",
            "                                                                 \n",
            " conv_dw_1_bn (BatchNormaliz  (None, 112, 112, 8)      32        \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_1_relu (ReLU)       (None, 112, 112, 8)       0         \n",
            "                                                                 \n",
            " conv_pw_1 (Conv2D)          (None, 112, 112, 16)      128       \n",
            "                                                                 \n",
            " conv_pw_1_bn (BatchNormaliz  (None, 112, 112, 16)     64        \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_1_relu (ReLU)       (None, 112, 112, 16)      0         \n",
            "                                                                 \n",
            " conv_pad_2 (ZeroPadding2D)  (None, 113, 113, 16)      0         \n",
            "                                                                 \n",
            " conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 16)       144       \n",
            "                                                                 \n",
            " conv_dw_2_bn (BatchNormaliz  (None, 56, 56, 16)       64        \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_2_relu (ReLU)       (None, 56, 56, 16)        0         \n",
            "                                                                 \n",
            " conv_pw_2 (Conv2D)          (None, 56, 56, 32)        512       \n",
            "                                                                 \n",
            " conv_pw_2_bn (BatchNormaliz  (None, 56, 56, 32)       128       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_2_relu (ReLU)       (None, 56, 56, 32)        0         \n",
            "                                                                 \n",
            " conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 32)       288       \n",
            "                                                                 \n",
            " conv_dw_3_bn (BatchNormaliz  (None, 56, 56, 32)       128       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_3_relu (ReLU)       (None, 56, 56, 32)        0         \n",
            "                                                                 \n",
            " conv_pw_3 (Conv2D)          (None, 56, 56, 32)        1024      \n",
            "                                                                 \n",
            " conv_pw_3_bn (BatchNormaliz  (None, 56, 56, 32)       128       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_3_relu (ReLU)       (None, 56, 56, 32)        0         \n",
            "                                                                 \n",
            " conv_pad_4 (ZeroPadding2D)  (None, 57, 57, 32)        0         \n",
            "                                                                 \n",
            " conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 32)       288       \n",
            "                                                                 \n",
            " conv_dw_4_bn (BatchNormaliz  (None, 28, 28, 32)       128       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_4_relu (ReLU)       (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " conv_pw_4 (Conv2D)          (None, 28, 28, 64)        2048      \n",
            "                                                                 \n",
            " conv_pw_4_bn (BatchNormaliz  (None, 28, 28, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_4_relu (ReLU)       (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 64)       576       \n",
            "                                                                 \n",
            " conv_dw_5_bn (BatchNormaliz  (None, 28, 28, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_5_relu (ReLU)       (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv_pw_5 (Conv2D)          (None, 28, 28, 64)        4096      \n",
            "                                                                 \n",
            " conv_pw_5_bn (BatchNormaliz  (None, 28, 28, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_5_relu (ReLU)       (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv_pad_6 (ZeroPadding2D)  (None, 29, 29, 64)        0         \n",
            "                                                                 \n",
            " conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 64)       576       \n",
            "                                                                 \n",
            " conv_dw_6_bn (BatchNormaliz  (None, 14, 14, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_6_relu (ReLU)       (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv_pw_6 (Conv2D)          (None, 14, 14, 128)       8192      \n",
            "                                                                 \n",
            " conv_pw_6_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_6_relu (ReLU)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 128)      1152      \n",
            "                                                                 \n",
            " conv_dw_7_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_7_relu (ReLU)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_7 (Conv2D)          (None, 14, 14, 128)       16384     \n",
            "                                                                 \n",
            " conv_pw_7_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_7_relu (ReLU)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 128)      1152      \n",
            "                                                                 \n",
            " conv_dw_8_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_8_relu (ReLU)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_8 (Conv2D)          (None, 14, 14, 128)       16384     \n",
            "                                                                 \n",
            " conv_pw_8_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_8_relu (ReLU)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 128)      1152      \n",
            "                                                                 \n",
            " conv_dw_9_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_9_relu (ReLU)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_9 (Conv2D)          (None, 14, 14, 128)       16384     \n",
            "                                                                 \n",
            " conv_pw_9_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_9_relu (ReLU)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_10 (DepthwiseConv2D  (None, 14, 14, 128)      1152      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_10_bn (BatchNormali  (None, 14, 14, 128)      512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_10_relu (ReLU)      (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_10 (Conv2D)         (None, 14, 14, 128)       16384     \n",
            "                                                                 \n",
            " conv_pw_10_bn (BatchNormali  (None, 14, 14, 128)      512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_10_relu (ReLU)      (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_11 (DepthwiseConv2D  (None, 14, 14, 128)      1152      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_11_bn (BatchNormali  (None, 14, 14, 128)      512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_11_relu (ReLU)      (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_11 (Conv2D)         (None, 14, 14, 128)       16384     \n",
            "                                                                 \n",
            " conv_pw_11_bn (BatchNormali  (None, 14, 14, 128)      512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_11_relu (ReLU)      (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 128)      0         \n",
            "                                                                 \n",
            " conv_dw_12 (DepthwiseConv2D  (None, 7, 7, 128)        1152      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_12_bn (BatchNormali  (None, 7, 7, 128)        512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_12_relu (ReLU)      (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv_pw_12 (Conv2D)         (None, 7, 7, 256)         32768     \n",
            "                                                                 \n",
            " conv_pw_12_bn (BatchNormali  (None, 7, 7, 256)        1024      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_12_relu (ReLU)      (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv_dw_13 (DepthwiseConv2D  (None, 7, 7, 256)        2304      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_13_bn (BatchNormali  (None, 7, 7, 256)        1024      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_13_relu (ReLU)      (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv_pw_13 (Conv2D)         (None, 7, 7, 256)         65536     \n",
            "                                                                 \n",
            " conv_pw_13_bn (BatchNormali  (None, 7, 7, 256)        1024      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_13_relu (ReLU)      (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d_2   (None, 1, 1, 256)        0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1, 1, 256)         0         \n",
            "                                                                 \n",
            " conv_preds (Conv2D)         (None, 1, 1, 1000)        257000    \n",
            "                                                                 \n",
            " reshape_2 (Reshape)         (None, 1000)              0         \n",
            "                                                                 \n",
            " predictions (Activation)    (None, 1000)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 475,544\n",
            "Trainable params: 470,072\n",
            "Non-trainable params: 5,472\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = MobileNet(input_shape=None, alpha=0.25, depth_multiplier=1, dropout=1e-3, \n",
        "                                 include_top=True, weights='imagenet', input_tensor=None, pooling=None, classes=1000)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaGjhRRmkqKI"
      },
      "source": [
        "###  Classify images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTFWBD9FkqKK",
        "outputId": "afa6c774-e56d-4fe9-842f-2d7032fab2f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted:\n",
            " [[('n04372370', 'switch', 0.08513701), ('n04376876', 'syringe', 0.08170768), ('n03937543', 'pill_bottle', 0.072473675), ('n04286575', 'spotlight', 0.06193055), ('n04548280', 'wall_clock', 0.060954913)]]\n"
          ]
        }
      ],
      "source": [
        "# Write the image name below\n",
        "\n",
        "img_path = 'download.png'\n",
        "\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "print('Predicted:\\n', decode_predictions(preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvvQWG_8kqKQ"
      },
      "source": [
        "###  Extract CNN features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rT0iPnxkqKS",
        "outputId": "188c8ea9-f3cf-4a77-84a7-a35907e9c207"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature Shape:\n",
            " (1, 1000)\n",
            "\n",
            "Features:\n",
            " [[8.45947000e-07 3.36881712e-05 3.74933043e-05 5.82506436e-05\n",
            "  3.58010555e-04 1.30481646e-06 1.19297079e-06 5.43353963e-07\n",
            "  7.97340022e-07 7.50879735e-07 8.03708957e-08 3.21906015e-07\n",
            "  5.28705527e-07 5.26068288e-06 4.23359688e-06 5.13450118e-07\n",
            "  1.13920839e-06 7.28586599e-07 1.18359048e-05 1.99680812e-06\n",
            "  2.22620724e-06 8.47011324e-06 6.69349492e-06 1.69132927e-05\n",
            "  2.88863475e-06 1.93076474e-07 9.55915584e-06 1.22065630e-05\n",
            "  6.92152298e-06 9.09219398e-06 2.12008757e-07 2.30802721e-06\n",
            "  5.01166369e-07 5.93039829e-07 1.14026693e-06 2.89345439e-06\n",
            "  1.54929894e-05 9.54080264e-08 1.02650365e-05 3.32314187e-07\n",
            "  1.11215127e-06 2.47342456e-07 1.20754251e-07 2.30538163e-07\n",
            "  7.79244090e-07 8.50762802e-08 5.35873414e-06 1.64435073e-06\n",
            "  1.74112049e-08 5.69942722e-06 2.72256566e-05 4.88349860e-06\n",
            "  2.27028281e-07 9.77943955e-07 2.69297487e-07 2.27126293e-06\n",
            "  4.70327450e-07 2.41511589e-09 1.23219452e-05 7.85076509e-07\n",
            "  1.16172828e-06 5.53317125e-09 5.15772669e-08 5.35015772e-07\n",
            "  4.40684380e-06 2.15316527e-06 5.01346619e-07 3.06644466e-07\n",
            "  9.23817140e-07 6.36167670e-06 1.09727250e-06 3.18060047e-04\n",
            "  4.03955710e-06 1.75128836e-04 6.13226148e-05 1.39724370e-05\n",
            "  7.05872390e-06 1.06437083e-05 7.28389614e-06 5.05378703e-04\n",
            "  1.81536925e-05 9.14083273e-07 1.03910156e-06 3.84841769e-07\n",
            "  1.55231746e-07 5.34510889e-07 4.57049254e-07 3.94861945e-06\n",
            "  4.55446326e-07 2.01702587e-05 5.77227688e-08 1.69310204e-06\n",
            "  1.81588675e-07 6.02606974e-07 1.56649388e-04 1.36590003e-07\n",
            "  2.95888572e-06 1.00044563e-05 1.82505715e-07 9.87835374e-05\n",
            "  1.95326546e-04 5.80626249e-07 4.50143204e-07 2.11548886e-05\n",
            "  2.38948792e-06 2.65378418e-07 3.23205836e-06 8.46647657e-04\n",
            "  1.01561136e-05 8.94002596e-07 4.75618117e-06 6.25680623e-05\n",
            "  4.65439552e-05 1.47742958e-05 4.48055944e-05 2.01187158e-05\n",
            "  8.42825375e-06 1.00675015e-05 2.11765439e-07 8.97517111e-07\n",
            "  1.75190189e-06 1.07815913e-06 5.33002151e-07 3.68026853e-08\n",
            "  7.29274120e-07 2.02347155e-06 7.30546250e-04 1.05763493e-05\n",
            "  3.91064987e-06 5.59236069e-05 7.47385184e-06 1.34533741e-06\n",
            "  1.89767597e-04 1.41882211e-07 1.15637667e-05 2.16410035e-06\n",
            "  4.37919334e-06 2.71908357e-05 2.83431888e-07 1.08891618e-06\n",
            "  9.76961473e-07 1.56296153e-06 3.09327277e-07 3.88720764e-05\n",
            "  1.94035601e-05 3.39077140e-08 1.45484807e-06 2.23808868e-07\n",
            "  8.02926024e-06 1.82235340e-06 1.33929268e-06 4.01955504e-06\n",
            "  3.68670112e-06 5.62646928e-05 2.90295538e-05 2.01347611e-05\n",
            "  3.31648857e-06 4.26234010e-06 5.61153399e-07 5.42159853e-07\n",
            "  9.82948677e-06 1.38385576e-06 8.09040955e-07 2.76611922e-06\n",
            "  5.18953300e-07 1.82726819e-06 5.63279855e-07 1.50901514e-07\n",
            "  1.77107245e-06 3.19880741e-07 2.36092683e-06 2.21008264e-07\n",
            "  8.17427335e-08 2.81434382e-07 3.27906650e-06 8.63880268e-06\n",
            "  6.89550802e-07 1.34914831e-06 5.44099930e-06 1.58932962e-05\n",
            "  2.42263764e-06 1.97602117e-06 7.49993387e-06 4.35688780e-05\n",
            "  1.25182423e-05 2.06603741e-04 6.19406710e-05 8.08312980e-05\n",
            "  2.10278972e-06 5.20321664e-05 2.23360476e-05 2.39037240e-06\n",
            "  3.69751615e-05 7.02028365e-06 2.64935406e-05 3.93492110e-06\n",
            "  4.47594939e-05 5.06405377e-05 1.62560973e-05 2.62280664e-04\n",
            "  8.56656188e-05 2.78749358e-05 1.10776009e-05 1.34498859e-03\n",
            "  1.19963239e-04 1.87918577e-05 6.32400315e-06 1.25152710e-05\n",
            "  2.10460439e-05 3.45359194e-06 1.32799494e-06 3.65102665e-06\n",
            "  1.12421731e-06 2.79207097e-06 4.93980087e-06 2.18485661e-06\n",
            "  5.05628395e-06 1.96118690e-05 1.49229606e-06 1.93260148e-05\n",
            "  3.94387207e-05 1.25735503e-04 6.81104393e-06 3.76959448e-04\n",
            "  7.90514387e-05 5.77367302e-07 1.16405436e-05 1.42207932e-06\n",
            "  9.77273157e-06 6.56073234e-06 1.61847606e-06 1.55706721e-06\n",
            "  6.71840171e-05 2.78417021e-04 4.34491130e-06 9.96203653e-07\n",
            "  4.46260401e-07 1.05319566e-06 1.55014357e-06 4.31477156e-06\n",
            "  2.71629847e-06 4.41559592e-07 4.38080588e-06 2.24074256e-06\n",
            "  3.63486811e-06 8.79458184e-06 2.47239143e-07 1.20179993e-06\n",
            "  4.37179870e-06 2.72306829e-06 1.75917137e-06 3.86327247e-06\n",
            "  2.69384967e-04 1.57985221e-06 2.21974660e-05 2.23491071e-07\n",
            "  9.81476187e-05 9.99931581e-06 8.73377285e-05 2.40094487e-05\n",
            "  2.12968080e-05 2.36522214e-06 2.40881836e-05 2.96153985e-06\n",
            "  4.30775754e-06 3.51044655e-05 1.92956304e-05 4.39998839e-05\n",
            "  3.06631051e-07 6.00555722e-06 2.97688603e-05 2.58959631e-07\n",
            "  2.49008326e-06 1.51280483e-05 1.49601090e-06 1.22418641e-07\n",
            "  5.49961271e-07 1.51342317e-06 3.33226296e-07 4.67436112e-05\n",
            "  7.01667886e-07 1.84226349e-06 1.84879161e-06 7.42902921e-05\n",
            "  6.74418470e-06 3.50933010e-06 2.68642498e-06 2.41486396e-06\n",
            "  6.91351090e-07 1.54496249e-07 1.15411808e-07 1.77470110e-06\n",
            "  1.64330663e-06 3.17651825e-07 1.86819375e-06 5.46953515e-06\n",
            "  2.67140167e-05 1.52541963e-06 4.20245186e-07 3.19249267e-07\n",
            "  6.15657609e-06 2.91274614e-06 7.54033954e-06 5.66430344e-06\n",
            "  4.63487004e-06 1.68347219e-06 1.16843212e-05 4.04393395e-05\n",
            "  1.27907333e-05 6.48980358e-06 6.57364071e-05 8.81502092e-06\n",
            "  4.22590674e-05 7.12703695e-05 7.01343160e-05 1.42411845e-05\n",
            "  1.78294968e-07 2.79684828e-05 5.62411913e-07 2.94691199e-06\n",
            "  1.72323616e-05 7.90708157e-07 1.68194362e-07 7.94202251e-08\n",
            "  1.66922950e-06 6.99706320e-08 1.66555481e-06 2.91238357e-05\n",
            "  1.58366947e-05 3.46326260e-06 1.82072498e-07 1.10906069e-06\n",
            "  1.38525347e-05 2.51134887e-04 7.58286774e-07 1.27571161e-06\n",
            "  7.38823616e-08 1.25727587e-04 1.13943934e-05 1.70439375e-06\n",
            "  8.89621333e-06 6.60394608e-06 2.25964823e-06 4.63251081e-06\n",
            "  1.46907735e-06 6.46511853e-06 8.64103549e-06 4.14453425e-05\n",
            "  2.41966382e-06 6.33985110e-07 5.12674092e-07 2.16152316e-07\n",
            "  7.25996642e-07 3.07625010e-06 1.32060595e-05 2.04910812e-05\n",
            "  9.06176683e-06 3.90263176e-06 2.10147255e-06 9.97940901e-07\n",
            "  1.94362951e-06 5.43535461e-05 5.24262805e-06 1.70737087e-06\n",
            "  2.86543400e-06 1.00260713e-05 1.07905353e-05 3.65162191e-06\n",
            "  1.35424725e-05 3.50819892e-06 1.57057073e-07 6.65378366e-07\n",
            "  2.22908275e-05 5.22676282e-06 1.77724069e-05 9.77064815e-07\n",
            "  1.44100932e-06 4.65245148e-06 3.23503127e-06 8.05616764e-06\n",
            "  4.75377328e-06 4.69029146e-06 2.91880247e-06 9.93913886e-07\n",
            "  2.31659874e-06 2.52680297e-06 2.00206705e-06 1.36115682e-06\n",
            "  1.69810028e-06 4.80994402e-07 3.36415184e-07 1.13535486e-06\n",
            "  5.78484503e-07 5.80226015e-07 1.55484872e-06 3.40105771e-06\n",
            "  3.96755377e-06 2.24312953e-05 8.00207781e-04 3.35775917e-06\n",
            "  8.50009474e-06 1.00360124e-03 2.89851159e-04 9.75496660e-04\n",
            "  2.33559334e-03 1.13029089e-02 1.59249088e-04 7.61377742e-04\n",
            "  1.35103916e-03 4.70714122e-02 1.35871102e-04 2.91054130e-05\n",
            "  1.48482202e-03 6.27002819e-03 1.70928048e-04 1.05427804e-04\n",
            "  2.94964921e-05 1.41945691e-03 1.99006405e-03 3.42080632e-04\n",
            "  1.05619307e-04 7.50912732e-05 9.62889826e-05 3.48611095e-04\n",
            "  2.83510017e-04 8.66368704e-04 9.38643178e-04 1.15218596e-03\n",
            "  6.58228528e-05 1.15200346e-05 1.02681838e-06 4.91652718e-05\n",
            "  2.54408835e-04 3.11103249e-05 2.29872512e-05 7.75906723e-04\n",
            "  3.05615831e-05 1.25589781e-03 1.76320167e-03 1.83763204e-05\n",
            "  7.00783930e-05 1.83420387e-04 1.28027075e-03 2.28833560e-05\n",
            "  7.14018006e-06 3.37186566e-06 1.31347682e-03 1.46973194e-04\n",
            "  6.75758638e-04 1.42295845e-03 1.22199690e-05 1.56053029e-05\n",
            "  2.69084035e-06 6.30017748e-05 2.40731661e-05 1.65179151e-03\n",
            "  2.63433438e-04 1.68520943e-04 5.12340057e-06 6.67712811e-06\n",
            "  1.86356818e-04 2.68183037e-04 2.89826683e-04 9.71434114e-04\n",
            "  6.69860048e-04 3.59710946e-04 1.37357521e-04 3.95383495e-06\n",
            "  2.45494972e-04 3.15012177e-04 1.46838017e-02 3.23645538e-04\n",
            "  1.46639213e-04 8.33133352e-04 4.39164796e-06 1.03671809e-04\n",
            "  4.90490811e-06 2.84129841e-04 1.35632884e-03 5.44688191e-05\n",
            "  1.91220059e-03 4.65833675e-03 4.03204991e-04 2.74171005e-04\n",
            "  2.70196833e-05 1.60142477e-03 4.53510525e-04 1.47363942e-04\n",
            "  9.86179220e-04 1.63606514e-04 4.11931287e-05 8.58628628e-05\n",
            "  1.63875186e-04 1.81188079e-04 1.51491922e-03 6.70132576e-04\n",
            "  1.73606022e-04 1.44611706e-03 1.64678262e-03 9.78552387e-04\n",
            "  9.72761598e-04 2.44128478e-06 7.42291331e-06 1.04941995e-04\n",
            "  2.90660537e-04 7.99433546e-05 7.47431477e-04 1.02571317e-03\n",
            "  3.84363532e-03 5.71070541e-06 1.43090985e-03 4.30848268e-05\n",
            "  3.19646858e-03 7.80303453e-05 2.92872892e-06 5.62911519e-05\n",
            "  1.07815256e-04 8.69517401e-03 1.11379915e-04 6.96172006e-04\n",
            "  2.17246816e-05 1.54405745e-04 2.20749207e-05 2.14722560e-04\n",
            "  6.32769486e-04 2.85477308e-05 8.35447048e-04 1.69625948e-03\n",
            "  2.02670763e-03 1.38915144e-04 3.36782970e-02 5.74996043e-03\n",
            "  1.06873085e-04 8.02351133e-06 1.00776837e-04 4.20934703e-05\n",
            "  7.94985099e-04 1.92644734e-06 4.21401666e-04 1.18664548e-05\n",
            "  4.73044493e-04 6.21284533e-04 7.57301517e-04 7.27039529e-04\n",
            "  2.68414478e-05 3.43532854e-04 3.41777061e-03 4.75443776e-05\n",
            "  1.10171306e-04 6.47334266e-04 7.10120425e-04 8.77217171e-05\n",
            "  8.66321148e-04 6.69175899e-03 2.30688718e-04 3.64339008e-04\n",
            "  8.64632384e-05 1.77013897e-03 4.24243248e-04 6.43160078e-04\n",
            "  6.48037894e-05 8.53777572e-04 8.14510859e-04 2.48653290e-04\n",
            "  3.65494052e-05 2.02910873e-04 4.98617283e-07 1.06929212e-04\n",
            "  1.15476114e-05 4.19819233e-04 3.43144493e-05 1.77531037e-04\n",
            "  8.28751421e-04 4.50993156e-07 2.32293809e-04 6.09329654e-05\n",
            "  2.05184870e-06 6.57791752e-05 8.96018355e-06 2.51448131e-03\n",
            "  9.87494332e-06 5.76281964e-05 1.10986957e-05 3.01087653e-04\n",
            "  3.45128588e-04 5.54259692e-04 1.49316751e-04 5.71708719e-04\n",
            "  2.91336299e-04 3.87569726e-03 9.51649563e-05 1.53375426e-04\n",
            "  7.00852717e-04 1.41138688e-03 7.03777914e-05 5.29863755e-04\n",
            "  8.80666834e-04 6.05327114e-06 5.63375303e-04 7.72631261e-04\n",
            "  4.54189815e-03 1.73759224e-06 2.82307774e-05 3.57640283e-06\n",
            "  1.68431696e-04 9.15971294e-04 1.53000921e-03 2.26540398e-03\n",
            "  3.89080287e-06 1.28300989e-03 8.30677072e-06 1.48018764e-03\n",
            "  3.68693463e-07 9.80849727e-05 4.95871427e-06 1.18677226e-05\n",
            "  1.10812252e-04 3.66476379e-05 1.26111569e-04 1.00514377e-02\n",
            "  5.74115256e-04 8.22313086e-05 1.04552112e-03 3.81776685e-04\n",
            "  4.34835638e-05 1.05611151e-04 2.77081877e-03 4.31945518e-05\n",
            "  7.16499635e-04 2.01704257e-04 3.62623098e-07 3.96270625e-04\n",
            "  2.41661735e-04 3.62504565e-04 1.12693269e-05 1.13030539e-04\n",
            "  1.83849799e-04 7.06922077e-03 7.53926861e-06 8.60305136e-07\n",
            "  3.95509269e-05 1.78257578e-05 9.86221130e-04 9.24368069e-05\n",
            "  4.74039167e-02 2.83524219e-06 1.65278802e-03 6.63638522e-04\n",
            "  9.85347782e-04 4.28233725e-05 4.69727721e-03 8.37631378e-05\n",
            "  4.00791287e-05 8.83672765e-05 1.61865610e-04 7.14136477e-05\n",
            "  2.03127987e-04 4.90297424e-03 2.21253003e-06 1.80327697e-04\n",
            "  3.76692973e-04 1.29532430e-06 1.59510819e-03 1.11646114e-04\n",
            "  1.17824669e-03 1.27104184e-04 5.03687945e-04 5.58105203e-05\n",
            "  1.82867167e-04 1.50340973e-04 1.85178069e-04 1.36542449e-05\n",
            "  1.28257602e-06 1.53099565e-04 3.80784762e-03 3.77200740e-05\n",
            "  6.70661902e-05 4.64408007e-03 3.34781034e-05 1.78216025e-04\n",
            "  6.45906766e-05 4.63255215e-04 1.09918343e-04 6.07239257e-04\n",
            "  8.43500038e-06 1.28365049e-04 1.20054574e-04 3.01711843e-04\n",
            "  2.29632854e-03 5.76979858e-07 1.04073899e-06 3.39053586e-05\n",
            "  7.65524979e-04 3.60617232e-05 3.05084366e-04 1.84281176e-04\n",
            "  9.70372988e-04 1.37272514e-06 2.27067620e-04 4.65124054e-03\n",
            "  1.01773196e-03 8.80896929e-04 9.94788206e-05 1.69877359e-03\n",
            "  1.31585577e-04 4.83172516e-05 2.04909811e-05 3.67467175e-04\n",
            "  1.04478408e-04 1.48952080e-04 1.55998720e-02 2.07373896e-03\n",
            "  2.18922825e-04 3.60955810e-03 1.32476926e-04 8.59465445e-07\n",
            "  1.99791021e-03 6.05894638e-05 1.06649248e-04 5.37043496e-04\n",
            "  7.24736750e-02 3.18935090e-05 5.38759159e-05 1.95449884e-05\n",
            "  1.52703619e-03 3.73494113e-05 4.74363378e-06 4.84846714e-05\n",
            "  1.30722037e-04 9.28725640e-04 2.18347544e-04 7.50160485e-04\n",
            "  3.05864553e-04 5.96534926e-04 1.37033552e-04 1.94283643e-06\n",
            "  2.81321292e-04 7.96258028e-05 4.27691702e-06 1.54730697e-05\n",
            "  3.06204287e-03 7.88674424e-06 4.33097640e-03 3.35612218e-04\n",
            "  5.68929175e-03 1.12746423e-02 7.20051321e-05 2.22927192e-04\n",
            "  1.35459020e-04 1.11831643e-03 1.22145639e-05 2.47983462e-05\n",
            "  3.94489916e-07 1.58571661e-03 9.91826528e-04 6.36954443e-04\n",
            "  3.80410347e-04 7.66989018e-04 4.77663634e-05 1.31801731e-04\n",
            "  1.35619880e-03 2.80879787e-04 1.09286331e-04 2.77859345e-03\n",
            "  2.62344605e-03 6.26669556e-04 2.66337331e-04 8.01709853e-03\n",
            "  5.03393539e-06 3.34133441e-03 7.49651178e-07 5.88903436e-04\n",
            "  7.63472985e-04 2.96798506e-04 2.74934519e-06 1.89640673e-06\n",
            "  5.42567468e-05 1.73488181e-04 2.70774169e-03 3.44105138e-05\n",
            "  8.94427358e-05 2.45227071e-04 2.98076239e-03 2.01118607e-02\n",
            "  9.17336065e-03 6.23957612e-06 4.87060612e-03 1.53981062e-04\n",
            "  4.51766973e-05 8.40443536e-05 2.33199753e-04 7.95627595e-04\n",
            "  1.02542550e-03 1.15944986e-05 3.03415139e-03 1.45429385e-05\n",
            "  2.52655609e-05 7.55857172e-07 8.75048514e-04 7.33991183e-05\n",
            "  3.81723366e-04 4.29177599e-05 3.07211048e-05 6.09597890e-04\n",
            "  1.13528338e-03 2.45727006e-05 2.80648169e-06 2.47274875e-04\n",
            "  2.66114557e-06 1.42945180e-04 1.48155948e-03 8.93838611e-03\n",
            "  1.82285008e-03 8.18261236e-04 3.55865996e-05 7.71819672e-04\n",
            "  1.31793240e-05 1.08980912e-05 6.19305484e-02 7.26977421e-04\n",
            "  1.42787867e-05 4.17787078e-06 7.97790744e-06 1.10733445e-05\n",
            "  6.82234895e-06 2.19847461e-05 2.46240990e-03 5.62847359e-03\n",
            "  5.15821390e-04 3.33229473e-05 6.30169758e-04 7.49842147e-05\n",
            "  1.24214188e-04 1.07598622e-04 5.55780889e-06 7.30909014e-05\n",
            "  1.71958920e-04 1.08608074e-04 1.35371854e-04 1.44243997e-04\n",
            "  2.58315890e-03 5.55533416e-06 5.65767914e-06 1.02975417e-03\n",
            "  8.51370096e-02 8.17076787e-02 8.49419623e-04 1.65298581e-04\n",
            "  1.00176898e-03 3.52678471e-05 6.06817812e-05 3.42381396e-03\n",
            "  7.48765597e-05 9.88183001e-06 8.93114367e-04 2.27443103e-04\n",
            "  2.01516668e-05 4.07963307e-05 8.09171324e-05 1.31325633e-03\n",
            "  1.07768064e-05 5.64736547e-03 1.94650842e-04 3.96105861e-06\n",
            "  1.03850376e-04 4.95111544e-06 4.83833806e-04 4.64148732e-04\n",
            "  1.18179049e-03 3.40491965e-06 2.30524329e-05 1.25107845e-05\n",
            "  4.92335204e-03 2.49539647e-04 1.72709424e-05 6.40973121e-06\n",
            "  7.14841823e-04 1.20948993e-04 3.32228979e-03 1.62823897e-04\n",
            "  1.79459621e-05 6.31401828e-03 7.71091378e-04 7.04766571e-05\n",
            "  1.14425457e-04 1.33747506e-06 1.52116554e-04 5.42529676e-07\n",
            "  2.34695362e-05 1.28341548e-04 2.92707155e-05 2.85914890e-03\n",
            "  6.09549135e-02 4.17754418e-05 9.91359004e-04 1.46358053e-03\n",
            "  7.13993935e-03 8.42033623e-05 1.96053996e-03 8.43367670e-05\n",
            "  7.32551096e-03 2.43424984e-06 5.62905334e-04 4.70223196e-04\n",
            "  4.32851695e-04 2.17429306e-02 6.76944126e-07 7.98989204e-04\n",
            "  1.38337084e-03 2.83758622e-04 1.31766838e-05 2.09243663e-05\n",
            "  3.89002562e-05 7.32698070e-04 6.34163780e-06 6.65493935e-05\n",
            "  3.67280591e-04 3.57492991e-06 8.43615489e-05 1.34091265e-03\n",
            "  4.17396799e-03 7.89247046e-04 9.29916278e-05 8.73203608e-05\n",
            "  5.13164468e-06 5.86579517e-05 7.94861194e-07 5.00887836e-05\n",
            "  8.58283875e-06 7.55417350e-05 3.60762897e-07 2.93338453e-05\n",
            "  3.49065340e-05 4.02276055e-06 8.06629214e-06 5.58474712e-05\n",
            "  2.66023699e-06 6.43547901e-05 8.64845606e-06 5.57708290e-06\n",
            "  1.75866307e-06 6.52294716e-07 2.27449709e-06 2.99373733e-05\n",
            "  3.48605067e-06 1.95342068e-06 1.64663561e-06 9.49062989e-04\n",
            "  6.89209992e-05 3.89372053e-06 7.19486707e-05 4.17547672e-05\n",
            "  9.70537499e-08 5.71005194e-06 9.33096599e-05 4.25820417e-06\n",
            "  2.51530832e-06 2.76413857e-06 1.91212661e-04 5.91515663e-06\n",
            "  3.91783920e-04 1.19400593e-05 1.65029305e-05 2.54720760e-07\n",
            "  9.91181696e-06 5.45070861e-07 2.27316050e-03 1.17724871e-04\n",
            "  6.09131239e-04 2.34869985e-05 8.48255422e-06 1.26505882e-04\n",
            "  2.15696098e-04 1.40152554e-06 3.27244561e-05 5.08419413e-04\n",
            "  4.61443487e-05 4.92837862e-05 5.36632142e-04 1.99499232e-06\n",
            "  2.10390790e-05 8.65388392e-06 4.54807650e-06 1.37601499e-04\n",
            "  6.68021748e-05 1.58579296e-05 3.66697517e-09 1.73841618e-04\n",
            "  5.27426380e-07 2.45140768e-06 1.01630794e-05 1.84082441e-04\n",
            "  4.39730393e-05 7.77920150e-07 6.01765396e-06 6.95877952e-06\n",
            "  6.89069975e-06 1.95917823e-06 4.82110227e-05 5.18817781e-03]]\n"
          ]
        }
      ],
      "source": [
        "features = model.predict(x)\n",
        "print('\\nFeature Shape:\\n',features.shape)\n",
        "print('\\nFeatures:\\n',features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYHHR_bskqKY"
      },
      "source": [
        "###  Extract features from an arbitrary intermediate layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "uOrIUA2DkqKb",
        "outputId": "663824fe-a61c-49e3-a729-64ddea39a060"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-394c08beca9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_minimal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv_dw_2_relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconv_dw_2_relu_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_minimal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Features of conv_dw_2_relu:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconv_dw_2_relu_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mvalidate_kwargs\u001b[0;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[1;32m   1172\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'input')"
          ]
        }
      ],
      "source": [
        "model_minimal = Model(input=model.input, output=model.get_layer('conv_dw_2_relu').output)\n",
        "\n",
        "conv_dw_2_relu_features = model_minimal.predict(x)\n",
        "print('Features of conv_dw_2_relu:',conv_dw_2_relu_features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oPYajJZkqKh"
      },
      "source": [
        "### You can extract these features and use the base network as a feature extractor for your problems. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5z5cFn5kqKj"
      },
      "source": [
        "# Part 3: Deep Convolution Layer Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "Yjr6DcimkqKm",
        "outputId": "b81c5988-850e-46dc-cc16-0fe6d3165937"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-03f63042c631>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtutorials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.contrib'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import matplotlib as mp\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOMgk22xkqKr"
      },
      "source": [
        "### Extract Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6PBNav6kqKt"
      },
      "outputs": [],
      "source": [
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-nifFGhkqKy"
      },
      "source": [
        "### Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9LkN_paDkqKz"
      },
      "outputs": [],
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 784],name=\"x-in\")\n",
        "true_y = tf.placeholder(tf.float32, [None, 10],name=\"y-in\")\n",
        "keep_prob = tf.placeholder(\"float\")\n",
        "\n",
        "x_image = tf.reshape(x,[-1,28,28,1])\n",
        "hidden_1 = slim.conv2d(x_image,5,[5,5])\n",
        "pool_1 = slim.max_pool2d(hidden_1,[2,2])\n",
        "hidden_2 = slim.conv2d(pool_1,5,[5,5])\n",
        "pool_2 = slim.max_pool2d(hidden_2,[2,2])\n",
        "hidden_3 = slim.conv2d(pool_2,20,[5,5])\n",
        "hidden_3 = slim.dropout(hidden_3,keep_prob)\n",
        "out_y = slim.fully_connected(slim.flatten(hidden_3),10,activation_fn=tf.nn.softmax)\n",
        "\n",
        "cross_entropy = -tf.reduce_sum(true_y*tf.log(out_y))\n",
        "correct_prediction = tf.equal(tf.argmax(out_y,1), tf.argmax(true_y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEodGsOUkqK5"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UPBduFekqK6"
      },
      "outputs": [],
      "source": [
        "batchSize = 50\n",
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "for i in range(1001):\n",
        "    batch = mnist.train.next_batch(batchSize)\n",
        "    sess.run(train_step, feed_dict={x:batch[0],true_y:batch[1], keep_prob:0.5})\n",
        "    if i % 100 == 0 and i != 0:\n",
        "        trainAccuracy = sess.run(accuracy, feed_dict={x:batch[0],true_y:batch[1], keep_prob:1.0})\n",
        "        print(\"step %d, training accuracy %g\"%(i, trainAccuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OTeqbaJkqLA"
      },
      "source": [
        "### Testing accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-JBoLBAkqLB"
      },
      "outputs": [],
      "source": [
        "testAccuracy = sess.run(accuracy, feed_dict={x:mnist.test.images,true_y:mnist.test.labels, keep_prob:1.0})\n",
        "print(\"test accuracy %g\"%(testAccuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2BhkZBskqLI"
      },
      "source": [
        "### Get activation values and plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8DOheo-hkqLJ"
      },
      "outputs": [],
      "source": [
        "def getActivations(layer,stimuli):\n",
        "    units = sess.run(layer,feed_dict={x:np.reshape(stimuli,[1,784],order='F'),keep_prob:1.0})\n",
        "    plotNNFilter(units)\n",
        "    \n",
        "def plotNNFilter(units):\n",
        "    filters = units.shape[3]\n",
        "    plt.figure(1, figsize=(20,20))\n",
        "    n_columns = 6\n",
        "    n_rows = math.ceil(filters / n_columns) + 1\n",
        "    for i in range(filters):\n",
        "        plt.subplot(n_rows, n_columns, i+1)\n",
        "        plt.title('Filter ' + str(i))\n",
        "        plt.imshow(units[0,:,:,i], interpolation=\"nearest\", cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkoaARCnkqLO"
      },
      "source": [
        "### Input Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUdOll7bkqLQ"
      },
      "outputs": [],
      "source": [
        "imageToUse = mnist.test.images[0]\n",
        "plt.imshow(np.reshape(imageToUse,[28,28]), interpolation=\"nearest\", cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oZ5UZDkkqLV"
      },
      "source": [
        "### Activation in Layer 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5dxXfvPkqLX"
      },
      "outputs": [],
      "source": [
        "getActivations(hidden_1,imageToUse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay9gNAvrkqLd"
      },
      "source": [
        "### Activation in Layer 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rlb3LGrWkqLe"
      },
      "outputs": [],
      "source": [
        "getActivations(hidden_2,imageToUse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhqGvOEkkqLl"
      },
      "source": [
        "### Activation in Layer 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmkgnW5ckqLo"
      },
      "outputs": [],
      "source": [
        "getActivations(hidden_3,imageToUse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0awq5VogkqLt"
      },
      "source": [
        "# Part 4: Design Choices in Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OGnsygzkqLv"
      },
      "source": [
        "## Influence of convolution size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWVCTsJPkqLy"
      },
      "source": [
        "### Model with (3 x 3) Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5wWkLbAkqL0"
      },
      "outputs": [],
      "source": [
        "K.clear_session()\n",
        "start = timeit.default_timer()   \n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAuW0NOHkqL7"
      },
      "source": [
        "### Model with (7 x 7) Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnphlXbvkqL8"
      },
      "outputs": [],
      "source": [
        "# Write your code here \n",
        "\n",
        "# Use the same model design from the above cell "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by2WASoQkqMD"
      },
      "source": [
        "## Striding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h9XyTZKkqME"
      },
      "source": [
        "### Model with (7 x 7) Convolution with 2 Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K39I1weskqMF"
      },
      "outputs": [],
      "source": [
        "start = timeit.default_timer()   \n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(7, 7), strides=2, activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(16, (7, 7), strides=2, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz6_wR8GkqMK"
      },
      "source": [
        "## Padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3kln95ykqMM"
      },
      "source": [
        "### Model with (7 x 7) Convolution with Same Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QinhffvkkqMO"
      },
      "outputs": [],
      "source": [
        "start = timeit.default_timer()   \n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(7, 7), strides=1, padding='same', activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(16, (7, 7), strides=1, padding='same', activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLPfWDdYkqMT"
      },
      "source": [
        "## Pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMhAfYO0kqMV"
      },
      "source": [
        "### Model with (3 x 3) Convolution with Pooling (2 x 2) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMSL5flZkqMW"
      },
      "outputs": [],
      "source": [
        "start = timeit.default_timer()   \n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HsHtxt0kqMc"
      },
      "source": [
        "### Model with (3 x 3) Convolution with Pooling (3 x 3) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w9kCVL7kqMe"
      },
      "outputs": [],
      "source": [
        "# Write your code here \n",
        "\n",
        "# Use the same model design from the above cell "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzV7LwepkqMn"
      },
      "source": [
        "### What are your findings?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Amol Paliwal(5/4/22) CT CO III Year.Convolutional_Neural_Networks-checkpoint.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}